{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas\n",
    "import heapq\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visit_popularity = Counter()\n",
    "purchase_popularity = Counter()\n",
    "\n",
    "#создаём матрицу с колонками id и частот, записываем id (только 7000 товаров, т.к. попытки найти max id оказались неуспешными)\n",
    "matrix = np.zeros((7000,3))\n",
    "for i in range(7000):\n",
    "    matrix[i][0] = i\n",
    "\n",
    "#создаём списки, куда запишем отдельные числа\n",
    "data_visits = []\n",
    "data_purchases = []\n",
    "    \n",
    "with open('train.txt', 'r') as f:\n",
    "    for line in f.xreadlines():\n",
    "        visits, purchases = line.strip().split(';')\n",
    "        \n",
    "        #разбиваем строки на числа (с visits всё тип-топ, а вот purchase ругается)\n",
    "        data_visits.append(map(int, visits.split(\",\")))\n",
    "        \n",
    "        #data_purchases.append(map(int, purchases.split(\",\")))\n",
    "        \n",
    "#цикл для нахождения max id, успешно неработающий\n",
    "#a = data_visits[0][0]\n",
    "#for i in data_visits:\n",
    "#    for j in data_visits:\n",
    "#        if a < data_visits[i][j]:\n",
    "#            a = data_visits[i][j]\n",
    "\n",
    "        # TODO\n",
    "        \n",
    "        #попытки сортировки по частоте (такие же успешные, как поиск max id)\n",
    "        \n",
    "        # update visit_popularity\n",
    "        \n",
    "        #for i in data_visits:\n",
    "            #for j in data_visits:\n",
    "                #k = data_visits[i][j]\n",
    "                #matrix[k][2] = matrix[k][2] + 1\n",
    "        \n",
    "        # update purchase_popularity\n",
    "        \n",
    "        \n",
    "#data_visits  \n",
    "#data_purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_by_purchase(items, max_count):\n",
    "    return heapq.nlargest(max_count, OrderedDict.fromkeys(items), key=lambda x: purchase_popularity.get(x, 0))\n",
    "\n",
    "def recommend_by_visit(items, max_count):\n",
    "    return heapq.nlargest(max_count, OrderedDict.fromkeys(items), key=lambda x: visit_popularity.get(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(recommend, max_count, sessions_file):\n",
    "    with open(sessions_file, 'r') as f:\n",
    "        avg_recall = np.zeros(max_count)\n",
    "        avg_precision = np.zeros(max_count)\n",
    "        sessions_count = 0\n",
    "        for line in f.xreadlines():\n",
    "            visits, purchases = line.strip().split(';')\n",
    "            if purchases != '':\n",
    "                visits = visits.split(',')\n",
    "                purchases = purchases.split(',')\n",
    "                rec = recommend(visits, max_count)\n",
    "\n",
    "                #обязательно будет сделано, как только предыдущие пункты заработают :с\n",
    "                \n",
    "                # TODO\n",
    "                # update avg_recall\n",
    "                # update avg_precision\n",
    "                # update sessions_count\n",
    "\n",
    "    return pandas.DataFrame({\n",
    "            'k': np.arange(max_count) + 1,\n",
    "            'avg_recall@k': [round(x, 2) for x in avg_recall / sessions_count],\n",
    "            'avg_precision@k': [round(x, 2) for x in avg_precision / sessions_count]\n",
    "    }).set_index('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_metrics(recommend_by_purchase, 5, 'train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_metrics(recommend_by_purchase, 5, 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_metrics(recommend_by_visit, 5, 'train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculate_metrics(recommend_by_visit, 5, 'test.txt')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
